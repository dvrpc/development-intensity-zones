# Comments for helper_functions.py


##Note: Because underscores BEFORE LETTERS BUT NOT AFTER THEM are used to italicize words, sentences, paragraphs, etc in Obsidian, this Obsidian document has spaces instead of those ONLY FOR TEXT IN THIS OBSIDIAN DOCUMENT THAT'S OUTSIDE OF CODE LINES

##Script location: typology_experiments.helpers.helper_functions.py



```df = state_key.copy()```: Makes a copy of  resources.state_key. FOUND OUT HOW TO DUPLICATE A DATAFRAME FROM https://stackoverflow.com/questions/27673231/why-should-i-make-a-copy-of-a-data-frame-in-pandas 

```return df```: This creates a function that creates a new lookup table that's exactly the same as  resources.state_key except for the geo_key column by first making a copy of  resources.state_key and then making its geo_key column equal to whatever the user wants. AND REMEMBER THAT NO MATTER WHAT,  resources.state_key MUST ALREADY BE IN THE DATABASE BEFORE THIS FUNCTION IS RUN



```if "geo_key" in locals().keys(): pass else: geo_key = db.get_dataframe_from_query("SELECT geo_name, geo_key FROM _resources.geo_key")```: Brings in the geo_name and geo_key columns of  resources.geo_key only if the table hasn't already been loaded in earlier in the script. HOW IT DOES THIS: SAYS IF THERE'S A TABLE NAMED "geo_key" THAT'S ALREADY BEEN LOADED INTO THE SCRIPT AT THIS POINT, DO NOTHING, OTHERWISE, LOAD IN  resources.geo_key. ALSO NOTE HOW IN ORDER TO CONNECT TO THE DATABASE HERE, THE COMMANDS "from typology_experiments import Database, DATABASE_URL" AND "db = Database(DATABASE_URL)" NEED TO BE RUN OUTSIDE OF AND BEFORE THIS FUNCTION IN THIS SCRIPT. AND IN ORDER TO USE pd.DataFrame() OR ANY OTHER pandas COMMAND FOR THAT MATTER, THE COMMAND "import pandas as pd" NEEDS TO BE RUN OUTSIDE OF AND BEFORE THIS FUNCTION IN THIS SCRIPT AS WELL. FOUND OUT HOW TO GET A DICTIONARY WHERE EACH VALUE IS AN OBJECT CREATED IN A SCRIPT AND EACH KEY IS THE NAME OF EACH OF THOSE OBJECTS FROM https://stackoverflow.com/a/4458733 (IN TURN FOUND ON https://stackoverflow.com/questions/4458701/how-to-get-the-list-of-all-initialized-objects-and-function-definitions-alive-in ),  FOUND OUT HOW TO SEE IF A KEY IS IN A DICTIONARY USING AN IF ELSE STATEMENT FROM https://www.stackvidhya.com/check-if-key-exists-in-dictionary-python/#:~:text=Using%20Keys()-,You%20can%20check%20if%20a%20key%20exists%20in%20a%20dictionary,True%20else%2C%20it%20returns%20False%20. , AND FOUND OUT HOW TO DO NOTHING DURING AN IF ELSE STATEMENT IN PYTHON FROM https://www.educative.io/edpresso/what-is-pass-statement-in-python 

```df = pd.merge(df, geo_key[["geo_name", "geo_key"]], on="geo_name", how="left")```: TO ALLOW FOR THE SORTING OF THE geo_name VALUES of the data frame BY THEIR ORDER IN  resources.geo_key IN A DATAFRAME, THIS TABULAR JOINS  resources.geo_key'S geo_name AND geo_key COLUMNS TO THE DATA FRAME BASED ON THE geo_name COLUMN. THE PURPOSE OF SPECIFYING  resources.geo_key ONLY HAVING ITS geo_name AND geo_key COLUMNS IN THIS COMMAND IS THAT IF  resources.geo_key WAS ALREADY LOADED INTO THE SCRIPT BY THE TIME THIS FUNCTION IS USED IN THE SCRIPT, IT EXCLUDES THE geo_type COLUMN. FOUND OUT HOW TO TABULAR JOIN DATAFRAMES FROM https://stackoverflow.com/questions/43297589/merge-two-data-frames-based-on-common-column-values-in-pandas

```df = df.sort_values(["year", "geo_key"])```: Then sorts the dataframe first by the year column and then by the geo_key column (the geo_key column shows what order the geo_name values should be in BASED ON THE ORDER ESTABLISHED IN  resources.geo_key). FOUND OUT HOW TO SORT A DATAFRAME BY 2 COLUMNS FROM https://www.kite.com/python/answers/how-to-sort-a-pandas-dataframe-by-multiple-columns-in-python

```df = df[["year", "geo_key"]+[list(df.columns)[-2]]]```: Keeps only the columns of the data frame that I want and in the order that I want them in. IT DOES THIS BY FIRST SELECTING THE year AND geo_key COLUMNS, THEN TO THAT LIST OF COLUMNS TO KEEP, ADDS THE 2ND TO LAST COLUMN. FOUND OUT HOW TO GET THE 2ND TO LAST ITEM OF A LIST FROM https://www.tutorialspoint.com/How-to-get-the-second-to-last-element-of-a-list-in-Python#:~:text=Any%20element%20in%20list%20can,%2C%20use%20%2D2%20as%20index. 

```return df```: This creates a function that sorts a dataframe, first by its year column and then by its geo_key column (which also shows the order their geo_name values should be in). I GOT THE GENERAL STRUCTURE OF HOW TO MAKE THIS FUNCTION FROM AARON FRAINT BASICALLY. REMEMBER THAT NO MATTER WHAT,  resources.geo_key MUST ALREADY BE IN THE DATABASE, AND IN ITS  resources SCHEMA FOR THAT MATTER, BEFORE THIS FUNCTION IS RUN



```geo_key = db.get_dataframe_from_query("SELECT * FROM _resources.geo_key")```: Brings in  resources.geo_key only if  resources.geo_key hasn't already been loaded into the script this function is being used in. I WANT TO BRING IN ALL COLUMNS OF IT THIS TIME BECAUSE I WILL BASICALLY BE USING ALL COLUMNS OF IT THROUGHOUT THE FUNCTION

```regional_geo_key_county_id_5digs = db.get_dataframe_from_query("SELECT geo_key, county_id_5dig FROM _resources.dvrpc_key UNION SELECT geo_key, county_id_5dig FROM _resources.state_key UNION SELECT geo_key, county_id_5dig FROM _resources.pa_suburban_key")```: Creates a table containing all of the regional geo_key values' county_id_5dig values. IT DOES THIS BY USING SQL'S UNION FUNCTION TO MERGING/ROW BIND THE geo_key AND county_id_5dig COLUMNS OF  resources.dvrpc_key,  resources.state_key, AND  resources.pa_suburban_key TOGETHER INTO 1 BIG TABLE. FOUND OUT HOW TO USE SQL TO MERGE/ROW BIND MULTIPLE TABLES INTO ONE BIG ONE FROM https://www.postgresqltutorial.com/postgresql-union/

```county_grouping_info_values = [list(regional_geo_key_county_id_5digs[regional_geo_key_county_id_5digs["geo_key"]==i]["county_id_5dig"]) for i in county_grouping_info_keys]```: Gets the county_id_5dig values of the counties that make up those groupings, which will be the values of the eventual county_grouping_info dictionary. HOW IT DOES THIS: FOR EACH UNIQUE geo_key VALUE/KEY OF THE DICTIONARY, IT GETS A LIST OF THE county_id_5dig VALUES FOR IT FROM regional_geo_key_county_id_5digs. FOUND OUT HOW TO GET COLUMN VALUES BASED ON ANOTHER COLUMN'S VALUE FROM https://sparkbyexamples.com/pandas/pandas-extract-column-value-based-on-another-column/

```county_grouping_info = dict(zip(county_grouping_info_keys, county_grouping_info_values))```: To start getting the values of the county grouping records, creates a dictionary, where the keys are the geo_key values of the county groupings, and the values are the county_id_5dig values of the counties that make up those groupings. IT DOES THIS BY MAKING THE DICTIONARY'S KEYS THE VALUES ESTABLISHED 2 COMMANDS AGO, AND MAKING THE DICTIONARY'S VALUES THE VALUES ESTABLISHED IN THE PREVIOUS COMMAND

```df_county_grouping_totals = [pd.DataFrame(df[df.county_id_5dig.isin(list(county_grouping_info.values())[i])].groupby(["year"])[[list(df.columns)[-3]]].sum()) for i in range(len(county_grouping_info))]```: For each year, this starts the process of getting their county grouping totals. THIS COMMAND FIRST GROUPS TO THE DATAFRAME IN QUESTION BY YEAR, THEN GETS THE SUM OF THE 3RD TO LAST COLUMN (THIS IS THE COLUMN TO SUM, IT'S RIGHT BEFORE THE geo_key AND county_id_5dig COLUMNS, WHICH WERE ADDED TO THE DATAFRAME IN QUESTION BY THE PREVIOUS COMMANDS OF THIS FUNCTION) FOR EACH YEAR/GROUP, AND PUTS THAT RESULT INTO A SERIES (BASICALLY A COLUMN), WHERE THE COLUMN IS EACH YEAR'S COUNTY GROUPING TOTAL TO THE DATAFRAME IN QUESTION VALUE, AND THE INDEX SHOWS THE years. IT THEN TURNS THE RESULT INTO A DATAFRAME. BASICALLY FOUND OUT HOW TO DO FROM https://stackoverflow.com/a/56375132 (IN TURN FOUND ON https://stackoverflow.com/questions/56360610/sum-column-based-on-another-column-in-pandas-dataframe )

```[df_county_grouping_totals[i].insert(1, "geo_key", list(county_grouping_info.keys())[i]) for i in range(len(county_grouping_info))]```: For each year's county grouping total dataframe, this then puts in their respective geo_key columns. ALSO IGNORE THE "[None, None, None, None]" THAT GETS PRINTED HERE, THE COMMAND WORKS. FOUND OUT HOW TO GET A LIST OF A DICTIONARY'S VALUES FROM https://thispointer.com/python-get-first-value-in-a-dictionary/

```df_county_grouping_totals.reset_index(level=0, inplace=True)```: Turns df_county_grouping_totals' year index into a year column. FOUND OUT HOW TO TURN THE INDEX INTO A COLUMN FROM https://stackoverflow.com/a/20461206 (IN TURN FOUND ON https://stackoverflow.com/questions/20461165/how-to-convert-index-of-a-pandas-dataframe-into-a-column )

```df_county_grouping_totals = df_county_grouping_totals[["year", "geo_key"]+[list(df_county_grouping_totals.columns)[1]]]```: Reorders the columns of df_county_grouping_totals to be the order I want them in. THIS COMMAND NOTABLY PICKS OUT THE 2ND COLUMN (THE COLUMN IN POSITION 1 ACCORDING TO PYTHON), WHICH IS THE COLUMN SHOWING THE DATA THE TABLE SHOWS (EX. VMT, NUMBER OF VEHICLES, ETC)

```df = pd.concat([df[list(df_county_grouping_totals.columns)], df_county_grouping_totals])```: Merges/row binds/etc the dataframe containing the county grouping rows to to the data frame in question, which only contains the same columns that the dataframe containing the county grouping rows has. THIS SIMULTANEOUSLY MERGES/ROW BINDS THE 2 DATAFRAMES, KEEPS ONLY THE COLUMNS I WANT FROM THE DATAFRAME IN QUESTION, AND PUTS THOSE COLUMNS IN THE ORDER I WANT THEM IN BECAUSE THAT WAS DETERMINED IN THE PREVIOUS COMMAND BY DOING THIS FOR df_county_grouping_totals. SO IN THIS COMMAND, I'M TAKING THE NAMES OF THE COLUMNS AND THEIR ORDER IN df_county_grouping_totals AND SAYING THOSE ARE THE COLUMNS I WANT TO KEEP AND IN THAT ORDER IN THE DATA FRAME IN QUESTION 

```return df```: Creates a function that finds the county grouping totals for a dataframe, merges/row binds those to that dataframe, and then sorts that final dataframe, first by its year column and then by its geo_key column. THE STEPS THIS FUNCTION ROUGHLY FOLLOWS FOR THE DATAFRAME IN QUESTION: 1) FIRST GIVE EACH geo_name VALUE ITS geo_key VALUE FROM  resources.geo_key, 2) GIVE EACH geo_key VALUE ITS CORRESPONDING county_id_5dig VALUE FROM  resources.county_key, 3) CREATE A DICTIONARY BY IMPORTING FROM THE VARIOUS  key TABLES: ALL COUNTIES' county_id_5dig VALUES (THE DVRPC ONES), THE NJ COUNTIES' county_id_5dig VALUES, THE PA COUNTIES' county_id_5dig VALUES, AND THE PA SUBURBAN COUNTIES' county_id_5dig VALUES, 4) CREATE A LIST WHERE EACH DATAFRAME WITHIN IT IS EACH YEAR'S COUNTY GROUPING TOTALS (county_id_5dig IS USED INSTEAD OF geo_name LIKE HOW WAS DONE BEFORE), 5) MERGE/ROW BIND/ETC THAT LIST OF TABLES INTO 1 BIG TABLE, 6) MERGE/ROW BIND/ETC THAT TABLE BACK INTO THE DATAFRAME IN QUESTION, 7) DROP THE geo_name AND county_id_5dig COLUMNS FROM THE DATAFRAME IN QUESTION, 8) REORDER THE COLUMNS SO THAT IT'S year, geo_key AND EX. vmt, 9) MULTI-LEVEL SORT THE DATAFRAME IN QUESTION, FIRST BY THE year COLUMN AND THEN BY the geo_key COLUMN. AND REMEMBER THAT NO MATTER WHAT,  resources.geo_key,  resources.county_key,  resources.dvrpc_key,  resources.state_key AND  resources.pa_suburban_key MUST ALREADY BE IN THE DATABASE BEFORE THIS FUNCTION IS RUN



```df[df.columns.drop(list_of_variables_to_keep_as_string)] = df[df.columns.drop(list_of_variables_to_keep_as_string)].apply(pd.to_numeric, errors="coerce")```: Converts all of the data frame's columns except for the user-defined list of variables to keep as string from string to numeric at once. FOUND OUT HOW TO CONVERT ALL COLUMNS IN A DATAFRAME EXCEPT FOR ONE TO NUMERIC AT ONCE FROM https://stackoverflow.com/questions/36814100/pandas-to-numeric-for-multiple-columns 

```return df```: Creates a function that streams in census data using a user-generated URL, turns the streaming results into a data frame, and since the results all come in as string, converts all columns except for the ones the user chooses to numeric



```folder_paths_list = [x[0] for x in os.walk(directory_path)]```: Gets a list of all folder paths within the general directory. FOUND OUT HOW TO GET A LIST OF ALL FOLDERS WITHIN A DIRECTORY FROM https://stackoverflow.com/a/973488 (IN TURN FOUND ON https://stackoverflow.com/questions/973473/getting-a-list-of-all-subdirectories-in-the-current-directory )

```if keep_or_remove == "keep": folder_paths_list = list(filter(re.compile(filtering_text_pattern).search, folder_paths_list))```: Just keeps the Updated_Tables folders from the result. BASICALLY FOUND OUT HOW TO SUBSET A LIST BASED ON STRING PATTERN FROM https://stackoverflow.com/a/57670481 (IN TURN FOUND ON https://stackoverflow.com/questions/15403021/regular-expression-to-filter-list-of-strings-matching-a-pattern )

```elif keep_or_remove == "remove": folder_paths_list = list(filter(lambda x: not re.compile(filtering_text_pattern).search(x), folder_paths_list))```: Removes the folder paths I don't want from the result. FOUND OUT HOW TO DROP ITEMS FROM A LIST BASED ON STRING PATTERN FROM https://stackoverflow.com/a/57670481 (IN TURN FOUND ON https://stackoverflow.com/questions/15403021/regular-expression-to-filter-list-of-strings-matching-a-pattern ), AND FOUND OUT HOW TO DO MULTIPLE IF STATEMENTS IN AN IF ELSE STATEMENT ("elif") FROM https://www.tutorialspoint.com/python/python_if_else.htm



```file_paths_list = [item for sublist in file_paths_list for item in sublist]```: Flattens the file paths list so that it's just 1 big list of table file paths. FOUND OUT HOW TO FLATTEN A LIST FROM https://stackabuse.com/python-how-to-flatten-list-of-lists/ 

```if "remove" in remove_or_not_and_text_pattern_if_necessary: file_paths_list = list(filter(lambda x: not re.compile(remove_text_pattern).search(x), file_paths_list))```: Removes the file paths the user doesn't want from the result. AND IF THE USER SPECIFIES THEY WANT TO REMOVE ITEMS/STRINGS THE RESULT, DO SO, OTHERWISE PASS. FOUND OUT HOW TO DROP ITEMS FROM A LIST BASED ON STRING PATTERN FROM https://stackoverflow.com/a/57670481 (IN TURN FOUND ON https://stackoverflow.com/questions/15403021/regular-expression-to-filter-list-of-strings-matching-a-pattern ), AND FOUND OUT HOW TO CHECK IF A STRING CONTAINS A SUBSTRING FROM https://stackabuse.com/python-check-if-string-contains-substring/ 



```last_modified_file_times_list = [os.path.getmtime(i) for i in file_paths_list_name]```: Gets the last modified times of the files in the file paths list. FOUND OUT HOW TO DO FROM https://www.kite.com/python/answers/how-to-get-the-last-modified-time-of-a-file-in-python#:~:text=Use%20os.,point%20at%20which%20time%20starts).

```last_modified_file_times_list = [datetime.fromtimestamp(i).strftime("%m/%d/%Y, %H:%M:%S") for i in last_modified_file_times_list]```: Converts the date-time values in the last modified file times list to a more legible format. FOUND OUT HOW TO DO FROM https://stackoverflow.com/a/19502375 (IN TURN FOUND ON https://stackoverflow.com/questions/19501711/how-can-i-convert-os-path-getctime ) AND https://www.programiz.com/python-programming/datetime/strftime



```import gspread```: I FIRST HAD TO RUN THE LINES "pip3 install gspread" AND "pip3 install --upgrade google-api-python-client oauth2client" BEFORE RUNNING THIS COMMAND. FOUND OUT HOW TO DO FROM https://www.analyticsvidhya.com/blog/2020/07/read-and-update-google-spreadsheets-with-python/ AND https://stackoverflow.com/a/37868852 (IN TURN FOUND ON https://stackoverflow.com/questions/9690138/how-do-i-access-read-write-google-sheets-spreadsheets-with-python )

```from oauth2client.service_account import ServiceAccountCredentials```: This and the next 2 commands brings in the credits needed to import the Google Sheets table. ALSO FOUND OUT HOW TO DO FROM https://www.analyticsvidhya.com/blog/2020/07/read-and-update-google-spreadsheets-with-python/ 

```google_sheets_worksheet = google_sheets_workbook.worksheet(name_of_worksheet_containing_table)```: Then brings in the worksheet/tab that contains the table. FOUND OUT HOW TO DO FROM https://docs.gspread.org/en/latest/user-guide.html 

```google_sheets_table = pd.DataFrame(google_sheets_worksheet.get_all_records())```: Then finally brings in the table from that worksheet/tab. ALSO FOUND OUT HOW TO DO FROM https://docs.gspread.org/en/latest/user-guide.html 

```return google_sheets_table```: Creates a function that streams in a table from a Google Sheets workbook. TO ENSURE THIS FUNCTION WORKS, THE USER HAS TO GO INTO THE GOOGLE SHEETS WORKBOOK TO SHARE IT AS AN EDITOR WITH THEIR client_email AS SPECIFIED IN THAT JSON THAT CONTAINS THEIR CREDENTIALS. FOUND OUT HOW TO DO THAT/ENSURE THIS WORKS FROM https://docs.gspread.org/en/latest/oauth2.html (IN TURN FOUND THROUGH https://github.com/burnash/gspread ), AND FOUND OUT ABOUT THIS STEP IN GENERAL FROM https://www.analyticsvidhya.com/blog/2020/07/read-and-update-google-spreadsheets-with-python/



```if unique_or_all == "unique": field_info_list = [list(new_tables_info_df_name[new_tables_info_df_name[table_name_column_name]==i][field_name].unique()) for i in list_of_table_names]```: For every new or old table name, gets the unique field name (ex. temporal, etc) field info, including blanks for now. HOW THIS COMMAND WORKS: 1) SUBSETS THE NEW OR OLD TABLES INFO DATA FRAME WHERE IT'S JUST THE RECORDS WHERE new_table_name OR old_table_name EQUALS THAT NEW OR OLD TABLE NAME/VALUE, 2) CREATES A LIST CONTAINING JUST THE UNIQUE VALUE OF THAT SUBSETTED DATA FRAME'S FIELD TYPE NAME (EX. temporal_field_name_and_dt, ETC) COLUMN, 3) DOES THAT EXACT PROCESS FOR EACH NEW OR OLD TABLE NAME/VALUE IN THE LIST OF NEW TABLE NAMES

```if field_name not in ["value_field_name_and_dt", "temporal_field", "old_table_temporal_field", "category_entry", "geo_key", "string_for_query", "old_table_name", "new_table_name_dict_item", "new_table_temporal_field", "temporal_field_for_query", "temporal_field_for_query_step1", "columns_to_order_by", "geo_field", "category_field", "value_field", "most_of_query_string"]: [i.remove(" ") for i in field_info_list if len(i) > 1]```: Excludes the one-space blanks only from tables which have at least 1 field of the type the user chooses, only if it's not certain fields being dealt with. FOUND OUT HOW TO REMOVE AN ITEM FROM A LIST BASED ON THE ITEM STRING VALUE FROM https://www.programiz.com/python-programming/methods/list/remove , AND FOUND OUT HOW TO CHECK IF AN ITEM ISN'T IN A LIST FROM https://www.adamsmith.haus/python/answers/how-to-check-if-an-element-is-not-in-a-list-in-python 



```owner_types = pdfplumber.open(BytesIO(requests.get("https://www.fhwa.dot.gov/bridge/mtguide.pdf").content)).pages[22].extract_text()```: Scrapes the text from the 23rd page of the NBI data dictionary PDF. IT DOES THIS BY: 1) CREATING A REQUEST TO GET THE DATA FROM THIS URL, 2) USING THAT REQUEST, STREAMS IN THE CONTENT OF THE PDF AND HOLDS IT AS A PDF OBJECT, 3) SINCE THE TABLE I WANT IS ONLY ON THE 23RD PAGE OF THE PDF, GOES TO THE 23RD PAGE OF THE PDF, AND 4) EXTRACTS THE TEXT FROM THAT, BUT AT THIS POINT IT'S IN A NON-TABLE/NON-PANDAS DATA FRAME FORM. FOUND OUT HOW TO USE THE pdfplumber PACKAGE TO SCRAPE TEXT FROM A PDF PAGE FROM https://medium.com/analytics-vidhya/how-to-easily-extract-text-from-any-pdf-with-python-fc6efd1dedbe AND https://stackoverflow.com/questions/59905947/pdfplumber-to-handle-pdf-online 

```owner_types = re.split("(\d+)", owner_types)```: Splits the one big owner_types string into a list of multiple strings, where the numbers are in their own strings and the text are in their own strings. FOUND OUT HOW TO SPLIT A STRING INTO NUMEROUS NEW ONES WHERE NUMBERS ARE IN THEIR OWN STRINGS AND TEXT ARE IN THEIR OWN FROM https://blog.finxter.com/how-to-split-a-string-between-numbers-and-letters/ 

```owner_types = [re.sub(" +", "", i) for i in owner_types]```: Gets rid of all instances of 2 or more spaces from the strings. BASICALLY FOUND OUT HOW TO DO FROM https://stackoverflow.com/a/1546244 (IN TURN FOUND ON https://stackoverflow.com/questions/1546226/is-there-a-simple-way-to-remove-multiple-spaces-in-a-string )

```owner_types.remove("")```: Drops any empty list elements. FOUND OUT HOW TO REMOVE AN ITEM FROM A LIST BASED ON THE ITEM STRING VALUE FROM https://www.programiz.com/python-programming/methods/list/remove 

```owner_types = pd.DataFrame({maintenance_column_name:owner_types[0::2], "Meaning":owner_types[1::2]})```: Turns owner_types into a data frame, where the owner and maintenance values are the EVEN number-indexed items of the owner_types list, and the meanings are the ODD number-indexed items of that same list. FOUND OUT HOW TO EXTRACT THE EVEN AND ODD NUMBER-INDEXED ITEMS OF A LIST FROM https://stackoverflow.com/a/12433705 (IN TURN FOUND ON https://stackoverflow.com/questions/12433695/extract-elements-of-list-at-odd-positions )

```owner_types = owner_types.drop(columns=["Meaning"])```: Drops Meaning now that it's no longer needed. FOUND OUT HOW TO DROP A COLUMN FROM https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf